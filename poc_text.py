# -*- coding: utf-8 -*-
"""Poc.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TpCBT-dIPl7pTRG-zzMoY_9NqsuW0GUS
"""
import numpy as np
import sklearn
import pandas as pd
from sklearn.preprocessing import LabelEncoder

import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem.isri import ISRIStemmer

# Download the stopwords corpus if not already downloaded
nltk.download('stopwords')
nltk.download('punkt')




import re

def preprocess_text(text):
    # Remove numbers from the text
    text = re.sub(r'\d+', '', text)
    # Convert to lowercase
    text = text.lower()
    return text



import streamlit as st
import pandas as pd
import pickle

# Load your trained model
classifier, vectorizer = pickle.load(open('text_classifier.pkl', 'rb'))

st.title('Text Classification Tool')

# File uploader
uploaded_file = st.file_uploader("Choose an Excel file", type=['xlsx'])
if uploaded_file is not None:
    df_test = pd.read_excel(uploaded_file)
    X_test = df_test.v2
    # Sample text data
   text_data = X_test

   # Tokenization and Stop Words Removal
   stop_words = stopwords.words('french')
   stop_words.extend(stopwords.words('arabic'))
   stop_words.extend(['bonjour','bjr','سلام','عليكم','mon','ma','ال','client','cliente','conteste','_xd_','salam','non','via','de','du','en','la','pas','en',
                   'le','réclame','!','?','salamoalikom','merci','retrait','compte','réclamation','dh','dhs','ai','un','CLIENT','CLIENTE',
                   '~',',','.','_','2023','date','montant','mad','/2023','dun'])
   stop_words = set(stop_words)
   processed_text_data = []
   for text in text_data:
       word_tokens = word_tokenize(text)
       # Stemming (using ISRIStemmer)
       #stemmer = ISRIStemmer()
       #word_tokens = [stemmer.stem(token) for token in word_tokens]
       filtered_text = [word for word in word_tokens if word.lower() not in stop_words]
       processed_text = ' '.join(filtered_text)
       processed_text_data.append(processed_text)
    

X_test=processed_text_data
    X_text=[preprocess_text(text) for text in X_test]
    X_test_vect = vectorizer.transform(X_test)
    predictions = classifier.predict(X_test_vect)  # adjust the column name
    df_test['predictions'] = np.where(predictions==1,'Multicanal','Monétique')
    st.write(df_test)







